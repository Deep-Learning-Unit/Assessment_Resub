{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFSR10dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8gUcNRWt-QX",
        "colab_type": "text"
      },
      "source": [
        "**Mount google drive**\n",
        "\n",
        "This will mount the google drive for google colab and you will be able access contents of your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OZ2MjA3FMfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e05c719-0ada-4e80-d530-75570ee384fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "# Add your directory path here\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Assignments')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4gZ5edVuRN_",
        "colab_type": "text"
      },
      "source": [
        "**Importing libraries**\n",
        "\n",
        "The tf.keras.datasets package in TensorFlow provides prebuilt utility functions for loading many common datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugnlk4B3FydW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzXM37A8uy_u",
        "colab_type": "text"
      },
      "source": [
        "**Loading dataset**\n",
        "\n",
        "First, we load the CIFAR-10 dataset. This might take a few minutes to download the first time you run it, but after that the files should be cached on disk and loading should be faster.\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
        "\n",
        "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP3qKFqoF6_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bbb161bd-38ab-41cb-d080-ef1a256f50a4"
      },
      "source": [
        "def load_cifar10(num_training=50000, num_test=10000):\n",
        "    \"\"\"\n",
        "    Fetch the CIFAR-10 dataset from the web.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
        "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
        "\n",
        "\n",
        "    # Normalize the data: subtract the mean pixel and divide by std\n",
        "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "    X_train = (X_train - mean_pixel) / std_pixel\n",
        "    X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "X_train, y_train, X_test, y_test = load_cifar10()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "Train data shape:  (50000, 32, 32, 3)\n",
            "Train labels shape:  (50000,) int32\n",
            "Test data shape:  (10000, 32, 32, 3)\n",
            "Test labels shape:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaLV0E_2viDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start your code from here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
