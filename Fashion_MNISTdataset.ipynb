{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNISTdataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8gUcNRWt-QX"
      },
      "source": [
        "**Mount google drive**\n",
        "\n",
        "This will mount the google drive for google colab and you will be able access contents of your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OZ2MjA3FMfM",
        "outputId": "725096c0-6e31-46c5-a029-664f1841e3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "# Add your directory path here\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Assignments')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4gZ5edVuRN_"
      },
      "source": [
        "**Importing libraries**\n",
        "\n",
        "The tf.keras.datasets package in TensorFlow provides prebuilt utility functions for loading many common datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugnlk4B3FydW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzXM37A8uy_u"
      },
      "source": [
        "**Loading dataset**\n",
        "\n",
        "we will use the [Fashion-MNIST ](https://www.tensorflow.org/datasets/catalog/fashion_mnist) dataset which is provided within keras. This might take a few minutes to download the first time you run it, but after that the files should be cached on disk and loading should be faster.\n",
        "\n",
        "This dataset consists of data points representing articles of an online shop. Each article is characterized by an $28 \\times 28$ pixels grayscale image. Moreover, each article is associated with a label $y$ that indicates to which of $10$ classes (or produce categories) this article belongs. The entire dataset consists of $60000$ data points used as training and validation set and another $10000$ data points used as test set. \n",
        "\n",
        "The $10000$ data points in the test set must not be used for learning the ANN weights and also not for monitoring the progress (validation) of the gradient method. Indeed, the monitoring of the validation error is some form of model adjustment as we use the validation error to decide when to stop the gradient method.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP3qKFqoF6_s",
        "outputId": "e8f41fcc-3350-49a8-9563-cd05ae2fe18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "# Load the raw fashion-MNIST dataset and use appropriate data types and shapes\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        " \n",
        "\n",
        "# Normalize the data: subtract the mean pixel and divide by std\n",
        "mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "X_train = (X_train - mean_pixel) / std_pixel\n",
        "X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape:  (60000, 28, 28)\n",
            "Train labels shape:  (60000,) uint8\n",
            "Test data shape:  (10000, 28, 28)\n",
            "Test labels shape:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaLV0E_2viDj"
      },
      "source": [
        "# Start your code from here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}